{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cdd520-a78e-4e61-b81d-4c99bc73ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import langchain\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage,AIMessage\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://12205-m2hl4tqk-eastus.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-08-01-preview\",\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    "    openai_api_version=\"2024-08-01-preview\",\n",
    "    api_key=\"d7f27353b3b3463bb02b2708df922f35\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e16aff3-0fa7-45c8-9ade-2b2bca25a88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='中国共有34个省级行政区，其中包括23个省、5个自治区、4个直辖市和2个特别行政区。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 25, 'total_tokens': 64, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-cdedd16b-478c-4b28-b325-696a155c016b-0', usage_metadata={'input_tokens': 25, 'output_tokens': 39, 'total_tokens': 64, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"用中文回复\"),\n",
    "    HumanMessage(content=\"中国有几个省份\"),\n",
    "  \n",
    "]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937408a-2b30-4ff7-abad-d6c09253711d",
   "metadata": {},
   "source": [
    "# 输出解析器\n",
    "导入简单的输出解析器，从而得到只想处理字符串响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a46b4a-9cbf-437d-b148-d60d377e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3ea8e8-519a-4484-ba49-edcc5dc0b11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'中国共有34个省级行政区，包括23个省、5个自治区、4个直辖市和2个特别行政区。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "   SystemMessage(content=\"用中文回复\"),\n",
    "    HumanMessage(content=\"中国有几个省份\"),\n",
    "]\n",
    "result=model.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90009a99-6091-4151-af6d-0b19e45f668b",
   "metadata": {},
   "source": [
    "#### 可以将模型与此输出解析器进行“链式”连接，即每次都会调用此输出解析器。此链采用语言模型的输入类型（字符串或消息列表）并返回输出解析器的输出类型（字符串），如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806ee70e-af32-4ca9-b589-a78bc892a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1104950-491f-4508-afb0-67c9f6b6ad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'目前中国共有34个省级行政区，包括23个省、5个自治区、4个直辖市和2个特别行政区。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "   SystemMessage(content=\"用中文回复\"),\n",
    "    HumanMessage(content=\"中国有几个省份\"),\n",
    "]\n",
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f052df-8d72-4a1c-866b-1bcc14f25438",
   "metadata": {},
   "source": [
    "# 提示词模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cf2ab-617b-43c2-9aeb-4bbdb0af23ba",
   "metadata": {},
   "source": [
    "PromptTemplates是LangChain 中的一个概念，旨在直接将消息列表传递给语言模型。PromptTemplates通常是由用户输入和应用逻辑的组合构建而成的。这个应用逻辑通常会将原始用户输入转换为准备传递给语言模型的消息列表，常见的转换包括添加系统消息或使用用户输入格式化模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657a67a-d948-4939-8d12-542ca00a3940",
   "metadata": {},
   "source": [
    "### 创建一个 PromptTemplate，它将接收两个用户变量：\n",
    "language: 要翻译成的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32531e8-3af9-4ace-b134-ff1ac4557c1e",
   "metadata": {},
   "source": [
    "text: 要翻译的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ad4293-1e10-4021-b1ee-03078ceeb282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into eglish:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "result = prompt_template.invoke({\"language\": \"eglish\", \"text\": \"hi\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64059313-466f-4fae-be8c-97321fcf5c85",
   "metadata": {},
   "source": [
    "### 可以看到它返回的是一个ChatPromptValue，由两个消息组成。如果想直接访问这些消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a9de220-a2e7-40bf-91fd-65463527c597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into english:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()\n",
    "[SystemMessage(content='Translate the following into english:'), HumanMessage(content='hi')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb90504-236e-4d9e-8ac3-be0d18b355e6",
   "metadata": {},
   "source": [
    "# 使用LCEL连接组件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b7b4b-dda6-48c0-acf6-962f41689ab3",
   "metadata": {},
   "source": [
    "### 可以使用 | 操作符将其与上面的模型和输出解析器结合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc930b6-4a36-4897-a05f-a04431b1b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5721c69a-90cb-4a70-b1b5-e3470b38fe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"eglish\", \"text\": \"你好\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd671b5-3338-441a-b69b-fbb43941dddb",
   "metadata": {},
   "source": [
    "# 构建聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36cb91-62b9-4ae7-a5cc-0ea8ad9d0d8c",
   "metadata": {},
   "source": [
    "### 构建个聊天机器人，仅使用语言模型进行对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f536db-d467-486d-aade-065a862a6075",
   "metadata": {},
   "source": [
    "对话式RAG: 在外部数据源上启用聊天机器人体验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a959a-0ae0-4b3b-929c-6372d9b6d9c1",
   "metadata": {},
   "source": [
    "代理: 构建一个可以采取行动的聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e013dafc-98e8-402b-b06b-8c1aaa01a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import langchain\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage,AIMessage\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://12205-m2hl4tqk-eastus.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-08-01-preview\",\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    "    openai_api_version=\"2024-08-01-preview\",\n",
    "    api_key=\"d7f27353b3b3463bb02b2708df922f35\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb52426-98ce-44c8-b098-55620ce7d126",
   "metadata": {},
   "source": [
    "直接使用模型，ChatModel是LangChain的运行接口实例，它提供了一个标准接口供我们与之交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7151db55-9758-4ca0-8aa4-1dbc9c22ea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Kitty! How can I assist you today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "from langchain_core.messages import HumanMessage\n",
    "result=model.invoke([HumanMessage(content=\"My name is kitty\")])\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8521e-1194-4591-8af8-58b31d12bde5",
   "metadata": {},
   "source": [
    "继续提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7a301ef-673c-49c2-9eac-2b270870021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, as an AI language model, I don't have access to your personal information such as your name.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=model.invoke([HumanMessage(content=\"What's my name?\")])\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580af4e-5d7e-4088-827f-53bdb64ffa22",
   "metadata": {},
   "source": [
    "很明显，并未与之前的对话建立上下文的联系，从而无法回答问题。那么将整个对话历史传递给模型，会得到："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8236a3e6-df7c-4030-9ff6-aeda5bc61044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is kitty.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "result=model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm kitty\"),\n",
    "        AIMessage(content=\"Hello kitty! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c5ecb-5477-4a83-9589-79c450658724",
   "metadata": {},
   "source": [
    "### 可以使用消息历史类来包装模型，使其具有状态。通过跟踪模型的输入和输出，将其存储在某个数据存储中。 未来的交互将加载这些消息，并将其作为输入的一部分传递给链。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56b6629a-1b9d-4623-ba3a-e2704b78b9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting langchain_community\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/45/a7/b9f3cd12510fe9a5fe2dcd7f12d095b0d5bd95fb2cd9c5362de45ebc18f9/langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.5/2.5 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 1.0/2.5 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.3/2.5 MB 1.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.6/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.1/2.5 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (0.3.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (0.3.28)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (0.2.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/f9/00/57b4540deb5c3a39ba689bb519a4e03124b24ab8589e618be4aac2c769bd/pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/64/38/8d37b19f6c882482cae7ba8db6d02fce3cba7b3895c93fc80352b30a18f5/marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (2.10.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain_community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda\\envs\\langchain\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.13 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8b3b5-b4e8-433b-a19e-2b55705a5843",
   "metadata": {},
   "source": [
    "导入相关类并设置链，该链包装模型并添加此消息历史。一个关键部分是我们作为 get_session_history 传入的函数，这个函数预计接受一个 session_id 并返回一个消息历史对象，这个 session_id用于区分不同的对话，并应作为配置的一部分在调用新链时传入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3c3aab1-fbd6-4061-9e48-17394ab66964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a940e85b-ffbc-4c08-a276-de2a64706d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"aaa\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2f7dc76-fc0a-4d3d-9832-0f1e4506127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Kitty! How can I assist you today?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm kitty\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a38eb4f4-e033-4de2-87bd-6fbc181338e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Kitty, according to what you told me earlier.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b551d-08ff-4b9a-922b-226325cb6843",
   "metadata": {},
   "source": [
    "更改配置以引用不同的session_id，可以看到它开始新的对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9156650d-d93d-48a0-a169-7b22e720f796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, as an AI language model, I don't have access to your personal information such as your name.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"bbb\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2fe30-2118-4a4e-945d-8163d930d89c",
   "metadata": {},
   "source": [
    "## 提示词模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a0079-53a2-4e93-b68c-a57900f55ef5",
   "metadata": {},
   "source": [
    "#### 提示词模板可以将原始用户信息转换为大型语言模型可以处理的格式。在这种情况下，原始用户输入只是一个消息，我们将其传递给大型语言模型。比如添加一个带有一些自定义指令的系统消息（但仍然将消息作为输入）并且添加除了消息之外的更多输入。首先添加一个系统消息，我们将创建一个 ChatPromptTemplate，并且将利用 MessagesPlaceholder 来传递所有消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56f6b1bc-f825-4e3b-805b-c48a0e2585e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7253d8ca-54ef-43f8-b559-baf10453b3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Kitty! How can I assist you today?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm kitty\")]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e92afd-e664-48c1-ab38-a72ce52b0929",
   "metadata": {},
   "source": [
    "将其包装在与之前相同的消息历史对象中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95c537ee-6e30-41de-b21b-82b4e40e13fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Tom! How can I assist you today?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "config = {\"configurable\": {\"session_id\": \"ccc\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Tom\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd73a924-d9c0-4ba3-9739-ccf5d417c9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Tom.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7905856-4821-4cde-984a-ccc237129e19",
   "metadata": {},
   "source": [
    "再复杂一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6b2588d-2cda-47fc-866a-c7cc4546155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "643f9475-fee2-49f8-8d16-5e0b4b996e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 밥님! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm bob\")], \"language\": \"Korean\"}\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc586bdb-9eed-459f-bdf0-d859866d4476",
   "metadata": {},
   "source": [
    "将这个更复杂的链封装在一个消息历史类中。由于输入中有多个键，需要指定正确的键来保存聊天历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10a7f633-8b47-4c80-bfcd-738c48fd5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"ddd\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a855d4af-7301-4e15-87be-ef6f14965d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola Todd! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87982742-8b5f-4c54-bb8a-5d820f037beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tu nombre es Todd.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed8cf9-fcf9-4e71-be21-b8d594786d56",
   "metadata": {},
   "source": [
    "## 管理对话历史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94fe0c-9378-4e11-b1bb-eb5da9bed731",
   "metadata": {},
   "source": [
    "LangChain提供了一些内置的助手来管理消息列表。在这种情况下，使用trim_messages助手来减少发送给模型的消息数量。修剪器允许指定希望保留的令牌数量，以及其他参数，例如是否希望始终保留系统消息以及是否允许部分消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c4fc3e6-86c6-4833-81ae-bb1a9f5348c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "# pip install tiktoken\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "def str_token_counter(text: str) -> int:\n",
    "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "\n",
    "def tiktoken_counter(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"Approximately reproduce https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "    For simplicity only supports str Message.contents.\n",
    "    \"\"\"\n",
    "    num_tokens = 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    tokens_per_message = 3\n",
    "    tokens_per_name = 1\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            role = \"user\"\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            role = \"assistant\"\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            role = \"tool\"\n",
    "        elif isinstance(msg, SystemMessage):\n",
    "            role = \"system\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported messages type {msg.__class__}\")\n",
    "        num_tokens += (\n",
    "            tokens_per_message\n",
    "            + str_token_counter(role)\n",
    "            + str_token_counter(msg.content)\n",
    "        )\n",
    "        if msg.name:\n",
    "            num_tokens += tokens_per_name + str_token_counter(msg.name)\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "trim_messages(\n",
    "    messages,\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=tiktoken_counter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b16d4a4-2e41-404e-9215-e6ee4442dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=tiktoken_counter,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8f6c6-1774-4a24-ab3a-c42b5fc9ffd3",
   "metadata": {},
   "source": [
    "在链中使用它，我们只需在将 messages 输入传递给提示之前运行修剪器，现在如果尝试询问模型我的名字，它将不知道，因为我们修剪了聊天历史的那部分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec497b7e-612c-4493-9b9c-c40097348f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't know your name.\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\": \"Chinese\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5c3c6-8e81-406e-bf75-83b4456b4100",
   "metadata": {},
   "source": [
    "如果我们询问最近几条消息中的信息，那么它会记住："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faf1457f-9c15-4434-85c9-e153cf8c4630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"what\\'s 2 + 2\"'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"Eglish\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c03204-47da-4f90-ba6c-1b14097e8439",
   "metadata": {},
   "source": [
    "现在将其包装在消息历史中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ad11931d-bb6c-4858-aba2-254de975e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"fff\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42ffd0df-2acf-4d24-882e-b72d0559298e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't know your name as you haven't told me yet.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f534d16-e602-4245-b3d4-420aebba069f",
   "metadata": {},
   "source": [
    "声明姓名的第一条消息已被删除。此外，聊天历史中现在有两条新消息（我们最新的问题和最新的回答），这意味着以前可以在我们的对话历史中访问的更多信息现在不再可用。在这种情况下，最初的数学问题也已从历史中删除，因此模型不再知道它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0143ec72-d57b-4bc9-abfe-9f31c1f55754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have the ability to access your previous conversation history. Can you please remind me of the math problem you asked?\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685a521-b9fc-40b8-a39e-c39c5d8f9924",
   "metadata": {},
   "source": [
    "## 流式处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637bc2f-0507-400c-96c8-be7e15e3d18c",
   "metadata": {},
   "source": [
    "对于聊天机器人应用程序来说，流式处理很重要。由于大型语言模型有时可能需要一段时间才能响应，因此为了改善用户体验，大多数应用程序所做的一件事是随着每个令牌的生成流回，这样用户就可以看到进度。所有链都暴露一个.stream 方法，使用消息历史的链也不例外，我们可以使用该方法获取流式响应："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f236f36-6700-4ff4-83b5-f8ec0d1dbaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||Hi|,| Kitty|!| Do| you| mean| \"|tell| me| a| news|\"?| If| so|,| I| can| provide| you| with| a| recent| news| headline|:\n",
      "\n",
      "|\"|NASA|'s| Per|se|ver|ance| rover| successfully| lands| on| Mars|,| begins| mission| to| search| for| signs| of| ancient| life|\"||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"hi! I'm kitty. tell me a new\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    print(r.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d05b7-660d-44fd-9677-138556c5567d",
   "metadata": {},
   "source": [
    "# 向量存储和检索器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cb4f2-432d-4ce8-9f6f-de43db9387c4",
   "metadata": {},
   "source": [
    "## 文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb48e85-ef23-4e2c-bca2-d4d65ed915e9",
   "metadata": {},
   "source": [
    "#### LangChain 实现了一个 文档 抽象，旨在表示一个文本单元及其相关元数据。它有两个属性：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68233c-8e39-448f-84fb-6521c748bd21",
   "metadata": {},
   "source": [
    "page_content：一个表示内容的字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ee81-d6c3-4ca3-9982-b760d7da0745",
   "metadata": {},
   "source": [
    "metadata：一个包含任意元数据的字典，metadata属性可以捕获有关文档来源、与其他文档的关系以及其他信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0560442-e6e2-447c-9813-781904f2da6e",
   "metadata": {},
   "source": [
    "生成了五个文档，包含指示三个不同“来源”的元数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53b278a8-385b-4fad-9937-46bfe38d90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
    "        metadata={\"source\": \"fish-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
    "        metadata={\"source\": \"bird-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034e781-7aea-4828-90db-e14f85e3b4c6",
   "metadata": {},
   "source": [
    "## 向量存储"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
